{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCP5DAlkrXue",
        "outputId": "f3d45f91-7a6c-4b93-9f01-60ecfd97e07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pfG3bM75nM8U"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/데이터_전처리_파일_선박명.csv', encoding='cp949')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nV1kcraIoLVi"
      },
      "outputs": [],
      "source": [
        "# 대분류, 중분류, 소분류 데이터 전처리\n",
        "data = list(df['Machinery']  + ' ' + df['Assembly'] + ' ' + df['청구품목'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Upr1OQEpI_l",
        "outputId": "8af99f8d-2257-4811-ae67-11e37ec9b1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G67pkbOkQ4Q"
      },
      "source": [
        "대분류, 중분류, 소분류를 feature 값으로 사용하고, target 값으로는 COOLER, GASKET, GEAR, O-RING 등 61개 분류명을 사용하여 다중 분류 모델을 만들 수 있습니다.\n",
        "\n",
        "전처리 과정에서는 대분류, 중분류, 소분류를 텍스트로 받아와서 토큰화하여 리스트 형태로 만들고, target 값을 숫자로 인코딩하여 넘파이 배열 형태로 만들어줍니다. 그 후, 해당 데이터를 분류 모델에 학습시켜 예측 모델을 만들어서 새로운 입력 데이터에 대해 분류할 수 있습니다.\n",
        "\n",
        "예를 들어, 다음과 같은 코드로 분류 모델을 만들 수 있습니다. (사용하는 머신러닝 라이브러리와 분류 알고리즘에 따라 코드는 달라질 수 있습니다.)\n",
        "\n",
        " CountVectorizer를 사용하여 텍스트 데이터를 feature 벡터로 변환하고, LabelEncoder를 이용하여 target 값을 숫자로 인코딩하였습니다. 이후 train_test_split 함수를 사용하여 데이터를 train, test 데이터로 분리하고, OneVsRestClassifier를 사용하여 SVM 분류기를 만들어 분류 모델을 학습시켰습니다. 마지막으로, 새로운 입력 데이터를 예측하여 target 값을 출력하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qf58PNEfjccV"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fEzoKGfgje_9"
      },
      "outputs": [],
      "source": [
        "# 대분류, 중분류, 소분류 텍스트 데이터\n",
        "data = list(df['Machinery']  + ' ' + df['Assembly'] + ' ' + df['청구품목'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sFnUJRwvjm3z"
      },
      "outputs": [],
      "source": [
        "# target 값\n",
        "target =list(df['key2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vlq7mjLij186"
      },
      "outputs": [],
      "source": [
        "# CountVectorizer를 이용하여 feature 벡터 생성\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XjuU-Utvj6jL"
      },
      "outputs": [],
      "source": [
        "# LabelEncoder를 이용하여 target 값을 숫자로 인코딩\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uf-Vw5Aoj_Dk"
      },
      "outputs": [],
      "source": [
        "# train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jCY22Bkd3PBN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score # 정확도 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js6Wf98Q-i5N",
        "outputId": "916c77b7-1045-4deb-dd2c-e57f8e131c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9007494059586912\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=200, max_depth=200,random_state=0)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "predict1 = clf.predict(X_train)\n",
        "print(accuracy_score(y_train,predict1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ-VYZ_NAEsV",
        "outputId": "7d68ed1a-f800-4707-dee5-01fbd4e6afa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9007494059586912\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "predict1 = clf.predict(X_train)\n",
        "print(accuracy_score(y_train,predict1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}